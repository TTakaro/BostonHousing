{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information about homes in the Boston area. With a number of feature variables available, we aim to predict either median home value or an estimate of air quality from the remaining variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the csv to have all columns on the same row\n",
    "data = []\n",
    "with open('boston.csv', 'r') as file, open('boston_mod.csv', 'a') as file2:\n",
    "#with open(\"boston.csv\") as file:\n",
    "    for i,line in enumerate(file):\n",
    "        if i > 21:\n",
    "            if i % 2 == 0:\n",
    "                new_line = line.rstrip()\n",
    "            else:\n",
    "                new_line = new_line + line.rstrip()\n",
    "                #print(new_line.split())\n",
    "                line_float = [float(i) for i in new_line.split()]\n",
    "                data.append(np.array(line_float))\n",
    "                file2.write(new_line + '\\n')\n",
    "                \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = (['CRIM', #per capita crime rate by town\n",
    "                 'ZN', #proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "                 'INDUS', #proportion of non-retail business acres per town\n",
    "                 'CHAS', #Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "                 'NOX', #nitric oxides concentration (parts per 10 million)\n",
    "                 'RM', #average number of rooms per dwelling\n",
    "                 'AGE', #proportion of owner-occupied units built prior to 1940\n",
    "                 'DIS', #weighted distances to five Boston employment centres\n",
    "                 'RAD', #index of accessibility to radial highways\n",
    "                 'TAX', #full-value property-tax rate per $10,000\n",
    "                 'PTRATIO', #pupil-teacher ratio by town\n",
    "                 'B', #1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "                 'LSTAT', #% lower status of the population\n",
    "                 'MEDV']) #Median value of owner-occupied homes in $1000's\n",
    "feature_names = column_names # Extract the features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let MEDV (Median home value) or NOX (Nitric oxides concentraion in air) be the target variable\n",
    "boston = pd.DataFrame(data=data, columns=column_names)\n",
    "target_col = 'MEDV' #'NOX'\n",
    "\n",
    "X = boston.loc[:, boston.columns != target_col] # Features\n",
    "Y = boston.loc[:, boston.columns == target_col] # Target\n",
    "\n",
    "# 70% train, 20% test, 10% validation\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size = 0.3, random_state=1)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size = 0.67, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a series of pre-built models to find best performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN regression accuracy: 0.6047362193880585\n"
     ]
    }
   ],
   "source": [
    "### KNN Regression ###\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "KNNReg = KNeighborsRegressor(n_neighbors=3)\n",
    "KNNReg.fit(X_train, Y_train)\n",
    "# Use the trained KNN classifier to predict the targets for the testing feature sample\n",
    "Y_predict = KNNReg.predict(X_test)\n",
    "\n",
    "# Measure the accuracy of our classifier by comparing our predictions to our known target values\n",
    "print(\"KNN regression accuracy:\", KNNReg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression accuracy: 0.8036563298060967\n",
      "Bayesian Ridge regression accuracy: 0.7893805796381106\n"
     ]
    }
   ],
   "source": [
    "### Ridge Regression ###\n",
    "\n",
    "from sklearn import linear_model\n",
    "# Now lets try with a ridge classifier where we're doing some crossvalidation\n",
    "RidgeReg = linear_model.RidgeCV(alphas=0.5)\n",
    "RidgeReg.fit(X_train, Y_train)\n",
    "predict = RidgeReg.predict(X_test)\n",
    "\n",
    "print(\"Ridge regression accuracy:\",RidgeReg.score(X_test, Y_test))\n",
    "\n",
    "\n",
    "BayReg = linear_model.BayesianRidge()\n",
    "BayReg.fit(X_train, np.ravel(Y_train))\n",
    "predict = BayReg.predict(X_test)\n",
    "\n",
    "print(\"Bayesian Ridge regression accuracy:\",BayReg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression accuracy: 0.7974774427057956\n",
      "Lars Lasso regression accuracy: 0.8014240751546191\n"
     ]
    }
   ],
   "source": [
    "### Lasso models ###\n",
    "\n",
    "LassoReg = linear_model.Lasso(alpha=0.1)\n",
    "LassoReg.fit(X_train, Y_train)\n",
    "predict = LassoReg.predict(X_test)\n",
    "\n",
    "print(\"Lasso regression accuracy:\",LassoReg.score(X_test, Y_test))\n",
    "\n",
    "\n",
    "# Lasso Lars?\n",
    "LarsReg = linear_model.LassoLars(alpha=0.01)\n",
    "LarsReg.fit(X_train, Y_train)\n",
    "predict = LarsReg.predict(X_test)\n",
    "\n",
    "print(\"Lars Lasso regression accuracy:\",LarsReg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic regression accuracy: 0.8044337929853431\n"
     ]
    }
   ],
   "source": [
    "### Elastic net model ###\n",
    "\n",
    "ElasticReg = linear_model.ElasticNet(alpha=0.01)\n",
    "ElasticReg.fit(X_train, Y_train)\n",
    "predict = ElasticReg.predict(X_test)\n",
    "\n",
    "print(\"Elastic regression accuracy:\",ElasticReg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For median home value, the simple best performing models are the Ridge, Lars Lasso, and Elastic regressions, each giving just over 80% accuracy for this training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a custom built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Build a machine learning model by building up layers\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='swish'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer, loss function, and metric to evaluate quality of fit\n",
    "def R2_score(y_true, y_pred):\n",
    "    mse = K.square(y_pred - y_true)\n",
    "    mean = K.mean(y_true)\n",
    "    tss = K.square(y_true - mean)\n",
    "    return abs(1 - K.sqrt(mse/K.square(y_true)))\n",
    "\n",
    "# Define loss function\n",
    "#loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), \n",
    "              loss='mean_absolute_error', metrics=R2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.3450 - R2_score: 1.1729\n",
      "Epoch 2/25\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.9769 - R2_score: 0.6368\n",
      "Epoch 3/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.0646 - R2_score: 0.6624\n",
      "Epoch 4/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7863 - R2_score: 0.7152\n",
      "Epoch 5/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6508 - R2_score: 0.6821\n",
      "Epoch 6/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2856 - R2_score: 0.6893\n",
      "Epoch 7/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.9792 - R2_score: 0.7056\n",
      "Epoch 8/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8478 - R2_score: 0.6779\n",
      "Epoch 9/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3872 - R2_score: 0.7237\n",
      "Epoch 10/25\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.8095 - R2_score: 0.6148\n",
      "Epoch 11/25\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.2977 - R2_score: 0.6694\n",
      "Epoch 12/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5034 - R2_score: 0.6746\n",
      "Epoch 13/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2678 - R2_score: 0.6803\n",
      "Epoch 14/25\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.4879 - R2_score: 0.6720\n",
      "Epoch 15/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6587 - R2_score: 0.7055\n",
      "Epoch 16/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5076 - R2_score: 0.6720\n",
      "Epoch 17/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4423 - R2_score: 0.7123\n",
      "Epoch 18/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5106 - R2_score: 0.7128\n",
      "Epoch 19/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.8505 - R2_score: 0.6998\n",
      "Epoch 20/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0030 - R2_score: 0.7000\n",
      "Epoch 21/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5042 - R2_score: 0.7153\n",
      "Epoch 22/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.1017 - R2_score: 0.6891\n",
      "Epoch 23/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4239 - R2_score: 0.7226\n",
      "Epoch 24/25\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.8129 - R2_score: 0.6916\n",
      "Epoch 25/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3233 - R2_score: 0.7152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9a7dfa1300>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model predicts air quality with accuracy: 0.8156891465187073\n"
     ]
    }
   ],
   "source": [
    "# Use model to generate predictions for x_val\n",
    "predictions = model(X_val.values).numpy()\n",
    "#print(predictions)\n",
    "acc_NOX = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print(\"Our model predicts air quality with accuracy:\", acc_NOX[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change target variable from 'NOX' to 'MEDV'\n",
    "target_col = 'MEDV'\n",
    "\n",
    "# Need to redefine and resplit the data with new target variable\n",
    "X = boston.loc[:, boston.columns != target_col]\n",
    "Y = boston.loc[:, boston.columns == target_col]\n",
    "\n",
    "# 70% train, 20% test, 10% validation\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size = 0.3, random_state=1)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size = 0.67, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "12/12 [==============================] - 1s 2ms/step - loss: 12.9885 - R2_score: 0.6389\n",
      "Epoch 2/25\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 11.4424 - R2_score: 0.6241\n",
      "Epoch 3/25\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 9.5387 - R2_score: 0.6879\n",
      "Epoch 4/25\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.4617 - R2_score: 0.7058\n",
      "Epoch 5/25\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 8.0251 - R2_score: 0.7044\n",
      "Epoch 6/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8621 - R2_score: 0.6988\n",
      "Epoch 7/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6404 - R2_score: 0.7160\n",
      "Epoch 8/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0451 - R2_score: 0.7236\n",
      "Epoch 9/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.8706 - R2_score: 0.7164\n",
      "Epoch 10/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6776 - R2_score: 0.7165\n",
      "Epoch 11/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.1513 - R2_score: 0.7465\n",
      "Epoch 12/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.0641 - R2_score: 0.7430\n",
      "Epoch 13/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4192 - R2_score: 0.7244\n",
      "Epoch 14/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9216 - R2_score: 0.7555\n",
      "Epoch 15/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3478 - R2_score: 0.7303\n",
      "Epoch 16/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4312 - R2_score: 0.7460\n",
      "Epoch 17/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5359 - R2_score: 0.7332\n",
      "Epoch 18/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4695 - R2_score: 0.7167\n",
      "Epoch 19/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2516 - R2_score: 0.7451\n",
      "Epoch 20/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2498 - R2_score: 0.7332\n",
      "Epoch 21/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6554 - R2_score: 0.7683\n",
      "Epoch 22/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4634 - R2_score: 0.7699\n",
      "Epoch 23/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.1780 - R2_score: 0.7486\n",
      "Epoch 24/25\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7668 - R2_score: 0.7556\n",
      "Epoch 25/25\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.4484 - R2_score: 0.7636\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.1645 - R2_score: 0.8109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.1644816398620605, 0.8109233379364014]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "    tf.keras.layers.Dense(256, activation='swish'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), \n",
    "              loss='mean_absolute_error', metrics=R2_score)\n",
    "model2.fit(X_train, Y_train, epochs=25)\n",
    "\n",
    "model2.evaluate(X_val, Y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model predicts home value with accuracy: 0.8109233379364014\n"
     ]
    }
   ],
   "source": [
    "# Use model to generate predictions for x_val\n",
    "predictions = model2(X_val.values).numpy()\n",
    "#print(predictions)\n",
    "acc_MED = model2.evaluate(X_val, Y_val, verbose=0)\n",
    "print(\"Our model predicts home value with accuracy:\", acc_MED[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom built model ends up with a bit over 80% accuracy for both target variables. This is marginally more effective than the best pre-existing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
